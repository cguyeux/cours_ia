# TP8.1 ‚Äî S√©lection de variables explicatives

[‚¨ÖÔ∏è Retour au sommaire](../../LISEZMOI.md)

## Positionnement p√©dagogique
- **Dur√©e indicative** : 3 heures.
- **Niveau** : √©tudiants de 3e ann√©e de BUT Informatique (parcours IA/Data).
- **Comp√©tences vis√©es** : compr√©hension des crit√®res de s√©lection, mise en ≈ìuvre de pipelines scikit-learn, analyse critique des r√©sultats.

## Objectifs d'apprentissage
1. Identifier les variables pertinentes pour pr√©dire une cible binaire.
2. Comparer plusieurs approches de s√©lection et comprendre leurs hypoth√®ses.
3. Mesurer l'impact de la s√©lection sur les performances et la complexit√© des mod√®les.

## Mise en route
1. Charger le dataset Adult Income (`fetch_openml`).
2. S√©parer les features (`X`) de la cible (`y`).
3. Identifier les colonnes num√©riques et cat√©gorielles (`select_dtypes`).
4. Construire un `ColumnTransformer` minimal pour g√©rer les types de variables :
   ```python
   from sklearn.compose import ColumnTransformer
   from sklearn.preprocessing import OneHotEncoder

   numeric_features = X.select_dtypes(include=["int64", "float64"]).columns
   categorical_features = X.select_dtypes(include=["object", "category"]).columns

   preprocess = ColumnTransformer([
       ("num", "passthrough", numeric_features),
       ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_features),
   ])
   ```

> üí° *Astuce p√©dagogique* : V√©rifiez la taille des donn√©es transform√©es (`shape`) pour prendre conscience de l'explosion dimensionnelle li√©e au one-hot encoding.

## Activit√© 1 ‚Äî Analyse univari√©e (45 min)
1. **Objectif** : mesurer l'association de chaque variable ind√©pendante avec la variable cible.
2. **M√©thodes propos√©es** :
   - `SelectKBest` avec `chi2` (sur donn√©es cat√©gorielles encod√©es et positives) ;
   - `SelectKBest` avec `mutual_info_classif` (robuste aux relations non lin√©aires).
3. **Plan d'action** :
   - Int√©grer le `SelectKBest` dans un pipeline avec une r√©gression logistique.
   - Tester `k ‚àà {10, 20, 40}`.
   - Utiliser une validation crois√©e (`cross_val_score`, `StratifiedKFold`) pour estimer `accuracy`, `f1` et `roc_auc`.
4. **Analyse attendue** :
   - Graphique `k` vs `score` pour chaque m√©trique.
   - Identification des variables s√©lectionn√©es pour chaque `k` (lister les noms gr√¢ce √† `get_support`).
   - Commentaire : quels types de variables ressortent ? Y a-t-il des surprises ?

> üß™ *√Ä rendre* : tableau comparatif des scores, interpr√©tation √©crite (5 lignes).

## Activit√© 2 ‚Äî S√©lection bas√©e sur un mod√®le (60 min)
1. **Objectif** : utiliser un mod√®le capable de pond√©rer l'importance des variables pour d√©cider lesquelles conserver.
2. **Mod√®les sugg√©r√©s** :
   - `RandomForestClassifier` avec `SelectFromModel` ;
   - `LogisticRegression(penalty="l1", solver="liblinear")` pour appliquer une p√©nalit√© Lasso.
3. **√âtapes d√©taill√©es** :
   - Cr√©er deux pipelines s√©par√©s (for√™t al√©atoire vs r√©gression logistique p√©nalis√©e).
   - Ajuster l'hyperparam√®tre de r√©gularisation (`C`) ou le seuil d'importance pour contr√¥ler le nombre de variables retenues.
   - √âvaluer chaque pipeline via validation crois√©e (m√©triques : `f1`, `balanced_accuracy`, `roc_auc`).
4. **Questions de r√©flexion** :
   - Les variables s√©lectionn√©es par la for√™t sont-elles identiques √† celles du Lasso ? Pourquoi ?
   - Comment justifier le choix d'un seuil (par exemple `median`) pour `SelectFromModel` ?

> üìå *Aller plus loin* : visualiser les importances normalis√©es (`feature_importances_` ou `coef_`) et discuter de leur interpr√©tation.

## Activit√© 3 ‚Äî S√©lection s√©quentielle (45 min)
1. **Objectif** : comprendre les approches incr√©mentales (`SequentialFeatureSelector`).
2. **M√©thodologie** :
   - Utiliser une r√©gression logistique comme estimateur de base.
   - Configurer deux s√©lecteurs : `direction="forward"` et `direction="backward"`.
   - Limiter le nombre de variables recherch√©es (ex. `n_features_to_select=25`) pour contenir les temps de calcul.
3. **Consignes** :
   - Mesurer le temps d'ex√©cution (module `time`).
   - Comparer les scores de validation crois√©e aux m√©thodes pr√©c√©dentes.
   - Discuter des compromis entre performance et co√ªt de calcul.

> ‚è±Ô∏è *Attention* : documentez les temps d'ex√©cution dans le notebook pour argumenter vos choix.

## Activit√© 4 ‚Äî Impact sur XGBoost (30 min)
1. **Contexte** : XGBoost g√®re d√©j√† un m√©canisme de s√©lection interne via le gain d'information.
2. **Exp√©rimentation** :
   - Cr√©er un pipeline avec pr√©traitement minimal (`OneHotEncoder` uniquement pour les cat√©gories).
   - Entrainer deux mod√®les XGBoost :
     - `XGBClassifier` sur l'ensemble complet ;
     - le m√™me mod√®le sur les variables retenues par la m√©thode jug√©e la plus pertinente (Activit√©s 1 √† 3).
   - Comparer temps d'entra√Ænement, `f1`, `roc_auc`.
3. **Analyse** : commenter l'int√©r√™t (ou non) de filtrer les variables avant XGBoost.

## Synth√®se √† produire
- Tableau r√©capitulatif : m√©thode de s√©lection / nombre de variables / m√©triques principales / temps d'entra√Ænement.
- Conclusion (8 √† 10 lignes) :
  - Quelle m√©thode est la plus adapt√©e √† ce dataset ?
  - Quelles sont les limites observ√©es ?
  - Quels crit√®res utiliseriez-vous pour choisir une m√©thode dans un nouveau projet ?

## Ressources compl√©mentaires
- Documentation scikit-learn : [Feature selection](https://scikit-learn.org/stable/modules/feature_selection.html)
- Article de blog recommand√© : *Feature Selection Techniques in Machine Learning* (Analytics Vidhya).
- Tutoriel vid√©o (facultatif) : *Feature Selection in Python* (StatQuest).
