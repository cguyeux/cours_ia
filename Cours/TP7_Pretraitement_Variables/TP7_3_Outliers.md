# TP7.3 ‚Äî D√©tection et traitement des outliers

## Positionnement p√©dagogique
- **Dur√©e indicative** : 2h30.
- **Niveau** : BUT3 Informatique.
- **Comp√©tences vis√©es** : identification d'observations aberrantes, ma√Ætrise d'algorithmes de d√©tection, int√©gration dans un pipeline de machine learning.

## Objectifs d'apprentissage
1. Comprendre l'impact des outliers sur diff√©rentes familles de mod√®les.
2. Mettre en ≈ìuvre des techniques statistiques et algorithmiques de d√©tection.
3. Choisir une strat√©gie de traitement (suppression, caping, transformation) adapt√©e au contexte m√©tier.

## Pr√©paration
1. Reprendre le dataset Adult Income et les s√©parations `train`/`test` pr√©par√©es dans les TP pr√©c√©dents.
2. Conserver la liste des variables num√©riques (`numeric_features`).
3. Cr√©er un notebook d√©di√© pour consigner les analyses visuelles et statistiques.

## Activit√© 1 ‚Äî Diagnostic exploratoire (30 min)
1. Calculer pour chaque variable num√©rique : moyenne, √©cart-type, m√©diane, quantiles (Q1, Q3).
2. Visualiser les distributions avec des boxplots et histogrammes (`seaborn` recommand√©).
3. Identifier visuellement les valeurs extr√™mes et consigner vos observations (variable concern√©e, nombre de points suspects, hypoth√®ses m√©tier).

> üóíÔ∏è *Astuce* : pensez √† travailler sur un √©chantillon r√©duit (ex. 5 000 lignes) pour acc√©l√©rer les visualisations si besoin.

## Activit√© 2 ‚Äî M√©thodes statistiques (35 min)
1. Impl√©menter l'approche IQR (InterQuartile Range) :
   - Calculer `IQR = Q3 - Q1`.
   - D√©finir des seuils : `[Q1 - 1.5*IQR, Q3 + 1.5*IQR]`.
   - Compter le pourcentage de lignes √† l'ext√©rieur de ces seuils pour `capital-gain`, `capital-loss`, `hours-per-week`.
2. Impl√©menter le z-score :
   - Standardiser les variables.
   - Marquer comme outliers les points dont `|z| > 3`.
3. Comparer IQR vs z-score : quelles variables sont sensibles √† la m√©thode choisie ?

## Activit√© 3 ‚Äî D√©tection automatique (45 min)
1. Tester trois algorithmes : `IsolationForest`, `LocalOutlierFactor`, `OneClassSVM`.
2. Pour chacun :
   - Travailler sur les variables num√©riques standardis√©es (`StandardScaler`).
   - Ajuster l'hyperparam√®tre principal (`contamination` ou `nu`).
   - Visualiser les scores/anomalies via un scatter plot (PCA 2D) ou un histogramme des scores.
3. Comparer les ensembles de points d√©tect√©s par chaque m√©thode (utiliser des ensembles Python pour compter les intersections).
4. Discuter : quelle m√©thode semble la plus pertinente et pourquoi ? (vitesse, interpr√©tabilit√©, sensibilit√© aux param√®tres).

> ‚öôÔ∏è *Conseil* : encapsuler le scaler et l'algorithme dans un pipeline scikit-learn pour √©viter les fuites.

## Activit√© 4 ‚Äî Strat√©gies de traitement (30 min)
1. Impl√©menter trois strat√©gies :
   - **Suppression** : retirer les lignes marqu√©es comme outliers.
   - **Winsorisation** : tronquer les valeurs extr√™mes aux bornes d√©finies par IQR.
   - **Transformation logarithmique** : appliquer `np.log1p` sur `capital-gain` et `capital-loss`.
2. Pour chaque strat√©gie, r√©-entra√Æner :
   - Une r√©gression logistique (avec pipeline complet du TP7.2).
   - Un mod√®le XGBoost (param√®tres par d√©faut).
3. Comparer `f1`, `roc_auc` et le temps d'entra√Ænement.
4. Discuter : quelle strat√©gie maximise le compromis performance/stabilit√© ?

## Activit√© 5 ‚Äî Sensibilit√© des mod√®les (20 min)
1. Mesurer l'impact des outliers sur :
   - Les coefficients d'une r√©gression logistique (avant/apr√®s nettoyage).
   - Les profondeurs d'arbre apprises par XGBoost (`max_depth` effective via importance des arbres).
2. Documenter vos observations dans un tableau ou un court commentaire.

## Synth√®se attendue
- Tableau r√©capitulatif : m√©thode de d√©tection / pourcentage d'observations marqu√©es / strat√©gie appliqu√©e / impact sur les m√©triques.
- Recommandations (6 √† 8 lignes) :
  - Quelle m√©thode privil√©gieriez-vous dans un contexte industriel ?
  - Comment surveiller la r√©apparition d'outliers en production ?
  - Quels tests automatiseriez-vous (ex. alerte si >X % d'outliers) ?

## Ressources
- Documentation scikit-learn : [Outlier detection](https://scikit-learn.org/stable/modules/outlier_detection.html)
- Article : *Anomaly Detection Techniques in Python* (Towards Data Science).
- Tutoriel vid√©o : *Isolation Forest Explained* (StatQuest).
