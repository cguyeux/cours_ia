# TP7.2 ‚Äî Normalisation et encodage des variables

[‚¨ÖÔ∏è Retour au README](../../README.md)

## Positionnement p√©dagogique
- **Dur√©e indicative** : 3 heures.
- **Niveau** : BUT3 Informatique.
- **Comp√©tences vis√©es** : choix d'un sch√©ma de transformation adapt√© au type de donn√©es, mise en ≈ìuvre de pipelines, pr√©vention des fuites de donn√©es.

## Objectifs d'apprentissage
1. Comprendre pourquoi normaliser/standardiser les variables num√©riques.
2. Choisir un encodage pertinent pour les variables cat√©gorielles en fonction du mod√®le cible.
3. Construire des pipelines reproductibles combinant transformations et mod√®les de classification.

## Cadre de travail
- Dataset : Adult Income (`fetch_openml`).
- S√©parer `X` et `y`, puis d√©couper le dataset en `train`/`test` stratifi√©s (`train_test_split`).
- Conserver une partie du jeu de test *non transform√©e* jusqu'√† l'√©valuation finale (pas de `fit` sur le test !).

## Activit√© 1 ‚Äî Cartographier les types de variables (20 min)
1. Cr√©er un tableau r√©capitulatif listant pour chaque colonne : type (`num√©rique`/`cat√©gorielle`), nombre de modalit√©s (cat√©gorielles), pr√©sence de valeurs manquantes.
2. Visualiser rapidement la distribution de 3 variables num√©riques (`histplot` ou `boxplot`) et de 3 variables cat√©gorielles (`value_counts()` + diagramme en barres).
3. D√©duire les transformations potentielles (besoin de normalisation ? encodage ordinal pertinent ?).

## Activit√© 2 ‚Äî Choix et comparaison des scalers (45 min)
1. Construire trois pipelines identiques (pr√©traitement + r√©gression logistique) qui ne diff√®rent que par le scaler appliqu√© aux num√©riques :
   - `StandardScaler`
   - `MinMaxScaler`
   - `RobustScaler`
2. √âvaluer via validation crois√©e (`StratifiedKFold`, 5 folds) les m√©triques `accuracy`, `f1`, `roc_auc`.
3. Analyser l'impact sur la stabilit√© des coefficients (`coef_`) de la r√©gression.
4. Question de r√©flexion : quelles situations du monde r√©el justifient l'usage de chacun de ces scalers ?

> ‚úçÔ∏è *√Ä consigner* : un tableau comparatif des scores moyens et √©carts-types.

## Activit√© 3 ‚Äî Encodage des cat√©gories (60 min)
1. Impl√©menter trois strat√©gies :
   - `OneHotEncoder` (baseline).
   - `OrdinalEncoder` avec un ordre logique pour `education` (par exemple : du niveau le plus faible au plus √©lev√©).
   - `TargetEncoder` (via `category_encoders`).
2. Pour `TargetEncoder`, mettre en place une validation rigoureuse :
   - Utiliser `KFoldTargetEncoder` ou envelopper l'encodeur dans un pipeline avec `ColumnTransformer` + validation crois√©e pour √©viter les fuites.
3. √âvaluer chaque strat√©gie avec deux mod√®les : r√©gression logistique et k-NN (`KNeighborsClassifier`).
4. Comparer les performances et discuter des limites :
   - Explosion du nombre de colonnes (OneHot).
   - Risque de sur-apprentissage (TargetEncoder).
   - Perte d'information sur l'ordre r√©el (OrdinalEncoder mal configur√©).

> üìä *Livrable* : un graphique en barres comparant `f1` pour chaque couple (encodeur, mod√®le).

## Activit√© 4 ‚Äî Pipelines avanc√©s et bonnes pratiques (30 min)
1. Introduire `ColumnTransformer` imbriqu√© :
   ```python
   from sklearn.pipeline import Pipeline
   from sklearn.impute import SimpleImputer

   numeric_transformer = Pipeline([
       ("imputer", SimpleImputer(strategy="median")),
       ("scaler", StandardScaler()),
   ])

   categorical_transformer = Pipeline([
       ("imputer", SimpleImputer(strategy="most_frequent")),
       ("encoder", OneHotEncoder(handle_unknown="ignore")),
   ])

   preprocess = ColumnTransformer([
       ("num", numeric_transformer, numeric_features),
       ("cat", categorical_transformer, categorical_features),
   ])
   ```
2. Expliquer l'int√©r√™t d'imputer *dans* le pipeline (pour √©viter les fuites et assurer la reproductibilit√©).
3. Tester ce pipeline complet avec deux mod√®les : r√©gression logistique et SVM lin√©aire (`LinearSVC`).
4. Mesurer les temps d'entra√Ænement et discuter des diff√©rences de performances.

## Activit√© 5 ‚Äî Impact sur XGBoost (25 min)
1. Comparer deux pipelines :
   - XGBoost avec seulement l'encodage `OneHotEncoder` (pas de scaler).
   - XGBoost avec encodage cat√©goriel natif (`enable_categorical=True`) en convertissant les colonnes en `category` puis en `int`.
2. √âvaluer `roc_auc` et `average_precision`.
3. Discussion :
   - Quels avantages/inconv√©nients du support natif des cat√©gories par XGBoost ?
   - Dans quel cas conserveriez-vous un encodage one-hot malgr√© tout ?

## Synth√®se attendue
- Tableau final r√©capitulant pour chaque combinaison (scaler, encodeur, mod√®le) : temps de fit, nombre de features g√©n√©r√©es, `f1`, `roc_auc`.
- Commentaire (8 lignes) expliquant la combinaison retenue pour la suite du parcours.

## Ressources
- Documentation scikit-learn : [Preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html)
- Biblioth√®que `category_encoders` : [documentation officielle](https://contrib.scikit-learn.org/category_encoders/)
- Article : *Handling Categorical Data for Machine Learning* (KDNuggets).
