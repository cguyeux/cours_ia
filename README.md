# Cours d'introduction à l'IA

## Objectifs du cours
- Comprendre les principales familles de problèmes d'intelligence artificielle.
- Manipuler des jeux de données tabulaires avec Python et la bibliothèque pandas.
- Mettre en œuvre des algorithmes de machine learning pour la classification et la régression.
- Savoir évaluer et améliorer les performances des modèles en utilisant des métriques adaptées et des techniques de préparation des données.

## IA "prédictive"

Le but n'est pas forcément de réaliser tous les exercices : nous avons voulu proposer un contenu exhaustif afin de s'adapter aux profils variés des étudiants.

1. [**TP1 – Découverte de pandas**](IA%20pr%C3%A9dictive/TP1/TP_Pandas_Enonce.md) : prise en main de la manipulation de données tabulaires et des opérations courantes de nettoyage.
2. [**TP2 – Clustering**](IA%20pr%C3%A9dictive/TP2_Clustering/TP2_enonce.md) : mise en œuvre d'algorithmes de regroupement non supervisé (k-means, analyse visuelle de l'inertie, etc.).
3. [**TP3 – Classification supervisée**](IA%20pr%C3%A9dictive/TP3_Classification/TP_Classification_ML_Enonce_v3.md) : application d'algorithmes de classification et évaluation des performances.
4. [**TP4 – XGBoost avancé**](IA%20pr%C3%A9dictive/TP4_XGBoost/TP4_XGBoost_Avance.md) : découverte et paramétrage d'un modèle de gradient boosting pour la classification.
5. [**TP5 – Régression**](IA%20pr%C3%A9dictive/TP5_Regression/TP_Regression_Validation.md) : mise en place d'un pipeline de régression et analyse des métriques associées.
6. [**TP6 – Objectifs et métriques XGBoost**](IA%20pr%C3%A9dictive/TP6_XGBoost_Objectif_Metriques/TP6_XGBoost_Objectif_Metriques.md) *(facultatif)* : exploration d'objectifs personnalisés et des métriques avancées pour XGBoost.
7. [**TP7 – Prétraitement des variables**](IA%20pr%C3%A9dictive/TP7_Pretraitement_Variables/TP_Pretraitement_Variables.md) *(facultatif)* : techniques de sélection, normalisation, encodage et traitement des données déséquilibrées.
8. [**TP8 – Explicabilité et causalité avec XGBoost**](IA%20pr%C3%A9dictive/TP8_XGBoost_Explicabilite_Causalite/TP8_XGBoost_Explicabilite_Causalite.md) *(facultatif)* : analyse des importances, valeurs SHAP et introduction à l'inférence causale.
9. [**TP9 – Théorie de l'information et modèles arborescents**](IA%20pr%C3%A9dictive/TP9_Information_Theory/TP9_Information_Theory.ipynb) *(facultatif)* : entropie, information mutuelle et application à un jeu de données synthétique avec XGBoost ([visualiser sur nbviewer](https://nbviewer.org/url/https://raw.githubusercontent.com/ChristopheGuyeux/docs/main/cours/IA_BUT3/IA%20pr%C3%A9dictive/TP9_Information_Theory/TP9_Information_Theory.ipynb)).

Les TP 6 à 9 sont proposés pour aller plus loin et peuvent être réalisés en autonomie en fonction de votre progression.

## IA générative

Trois travaux pratiques sont proposés pour découvrir et approfondir l'IA générative :

1. [**TP1 — Premiers pas avec la génération de texte**](IA%20g%C3%A9n%C3%A9rative/TP1_LangChain_Mistral.md) : prise en main de LangChain et des modèles Mistral pour créer vos premiers prompts structurés.
2. [**TP2 — Sorties structurées avec LangChain et Mistral**](IA%20g%C3%A9n%C3%A9rative/TP2_Sorties_Structurees.md) : fiabilisation des réponses LLM à l'aide de schémas Pydantic et de chaînes orientées extraction d'informations.
3. [**TP3 — Systèmes RAG et vector stores**](IA%20g%C3%A9n%C3%A9rative/TP3_RAG_Embeddings.md) : conception d'un pipeline de retrieval augmented generation s'appuyant sur des embeddings et une base vectorielle.
4. [**TP4 — Les agents**](IA%20g%C3%A9n%C3%A9rative/TP4_Agents_LangChain.md) : orchestration d’agents LangChain capables de planifier des actions, d’appeler des outils (APIs, fonctions Python) et de coordonner un flux de résolution multi-étapes.
