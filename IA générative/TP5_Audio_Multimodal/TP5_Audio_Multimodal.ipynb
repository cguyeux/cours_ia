{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a202d00c-765d-420d-bae9-17fc5f3a6c6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## L'audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af0ac02-c87a-44f0-9b63-ae0560619bb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896cded-5641-402a-b7c8-2e9a62020ad9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "response = OpenAI().audio.speech.create(\n",
    "  model=\"tts-1-hd\",\n",
    "  voice=\"onyx\", # alloy, onyx, fable, echo\n",
    "  input=\"Coucou, comment allez-vous ?\"\n",
    ")\n",
    "response.with_streaming_response.method('mon_audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0222f-716e-4d3f-9f07-957ab65bd491",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e6de8-2eeb-44e2-88e3-28be8b4f579c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OpenAI().audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=open(\"mon_audio.mp3\", \"rb\"),\n",
    "  language=\"fr\"\n",
    ").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee9c72-f087-4909-b072-43f6f6811c9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "song = AudioSegment.from_mp3(\"mon_fichier.mp3\")\n",
    "transcription = ''\n",
    "for pas in range(0, 120, 20):\n",
    "    debut, fin = pas * 60 * 1000, (pas+20) * 60 * 1000\n",
    "    extrait = song[debut:fin]\n",
    "    if len(extrait) > 100:\n",
    "        extrait.export(f\"extrait_{pas}.mp3\", format=\"mp3\")\n",
    "        audio_file = open(f\"extrait_{pas}.mp3\", \"rb\")\n",
    "        transcription += client.audio.transcriptions.create(\n",
    "          model=\"whisper-1\", \n",
    "          file=audio_file\n",
    "        ).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0f2b0-c61a-4411-86c5-448410a9dfc4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0ca3a26-a54d-4b78-a330-3ece1415e665",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_data_url(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Lit l'image et renvoie une data URL prête à être insérée dans le payload.\n",
    "    \"\"\"\n",
    "    # Lecture du fichier image\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_bytes = img_file.read()  # Lecture binaire du contenu\n",
    "    # Encodage base64\n",
    "    b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    # Détection du MIME type selon l'extension\n",
    "    ext = os.path.splitext(image_path)[1].lower().lstrip(\".\")\n",
    "    mime = f\"image/{ext if ext != 'jpg' else 'jpeg'}\"\n",
    "    return f\"data:{mime};base64,{b64}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93ae8a23-f595-4254-8b97-f6798878394d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[0;32m----> 5\u001b[0m data_url \u001b[38;5;241m=\u001b[39m \u001b[43mencode_image_to_data_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmon_image.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      8\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m, in \u001b[0;36mencode_image_to_data_url\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m b64 \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(image_bytes)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Détection du MIME type selon l'extension\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m ext \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(image_path)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m mime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mext\u001b[38;5;250m \u001b[39m\u001b[38;5;241m!=\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb64\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "data_url = encode_image_to_data_url(\"mon_image.png\")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Que vois-tu sur cette image ?\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}}\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bf937-6eeb-41fb-94f3-6bb4621264bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=messages,\n",
    "    max_tokens=500,\n",
    "    temperature=0.0\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}