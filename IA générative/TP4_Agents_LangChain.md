# TP4 â€” Orchestration d'agents avec LangChain (â‰ˆ 2h)

[â¬…ï¸ Retour au sommaire](../LISEZMOI.md)

## Objectifs

- Comprendre les principes d'un agent pilotÃ© par un LLM et son exÃ©cuteur.
- Installer et configurer des outils courants (Wikipedia, Tavily, arXiv, Python REPL...).
- CrÃ©er, enrichir et orchestrer diffÃ©rents agents LangChain autour de cas d'usage concrets.
- Concevoir vos propres outils et composer plusieurs agents spÃ©cialisÃ©s.

## PrÃ©requis

- Python 3.10 ou supÃ©rieur.
- Avoir suivi les TP1 Ã  TP3 (maÃ®trise basique de LangChain, prompts, sorties structurÃ©es).
- Connaissances de base sur les API et les variables d'environnement.

## Ressources utiles

- [Documentation LangChain â€“ Agents](https://python.langchain.com/docs/modules/agents/)
- [LangSmith Hub](https://smith.langchain.com/hub) pour explorer des prompts d'agents prÃªts Ã  l'emploi.
- [Tavily](https://www.tavily.com/) pour crÃ©er une clÃ© d'API de recherche web.

---

## Ã‰tape 0 â€” Rappel : qu'est-ce qu'un agent ? (â‰ˆ 10 min)

Un **agent** est un systÃ¨me autonome propulsÃ© par un modÃ¨le de langage qui reÃ§oit des donnÃ©es en entrÃ©e et dÃ©cide des actions Ã  entreprendre en fonction de son objectif et des outils disponibles. Il combine :

- la **prise de dÃ©cision** (le LLM planifie les actions) ;
- l'**exÃ©cution** (un ou plusieurs outils rÃ©alisent l'action demandÃ©e) ;
- la **boucle de rÃ©troaction** (l'exÃ©cuteur d'agent transmet les rÃ©sultats au LLM pour la suite du raisonnement).

![SchÃ©ma conceptuel d'orchestration par agents](img/promptulate.png)

ğŸ‘‰ **Exercice 0.1** â€” En deux phrases, dÃ©crivez un cas d'usage professionnel oÃ¹ vous combineriez plusieurs agents spÃ©cialisÃ©s.

ğŸ‘‰ **Exercice 0.2** â€” Identifiez un outil (API, script, base de connaissances) que vous souhaiteriez exposer Ã  un agent LLM.

---

## Ã‰tape 1 â€” PrÃ©parer l'environnement (â‰ˆ 15 min)

1. CrÃ©ez un environnement virtuel et installez les dÃ©pendances minimales :
   ```bash
   python -m venv tp4_agents
   source tp4_agents/bin/activate  # Sous Windows : tp4_agents\Scripts\activate
   pip install langchain langchain-community langchain-openai langchain-mistralai wikipedia langchain-tavily arxiv python-dotenv
   ```
2. Dans un fichier `.env`, stockez vos clÃ©s :
   ```env
   TAVILY_API_KEY="votre-cle"
   MISTRAL_API_KEY="..."     # optionnel si vous utilisez Mistral
   OPENAI_API_KEY="..."       # optionnel si vous utilisez OpenAI
   ```
3. Chargez les variables dans vos scripts via `dotenv` ou `os.environ`.

ğŸ‘‰ **Exercice 1.1** â€” VÃ©rifiez votre installation en important `langchain`, `langchain_community.tools` et `langchain_openai` dans un shell Python.

ğŸ‘‰ **Exercice 1.2** *(optionnel)* â€” Ajoutez `pre-commit` pour automatiser le formatage/linting des scripts d'agents.

---

## Ã‰tape 2 â€” Premier outil : interroger Wikipedia (â‰ˆ 15 min)

Un agent simple peut se limiter Ã  un outil, ici `WikipediaQueryRun`.

```python
#%pip install --upgrade --quiet wikipedia
from langchain.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper

wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())
print(wikipedia.run("Alan Turing"))
```

ğŸ‘‰ **Exercice 2.1** â€” CrÃ©ez une fonction Python `resume_article(sujet: str) -> str` qui s'appuie sur l'outil Wikipedia et tronque la rÃ©ponse Ã  500 caractÃ¨res.

ğŸ‘‰ **Exercice 2.2** â€” Quels sont les avantages et limites d'un agent *mono-outil* dans vos projets ? Notez-les dans un fichier `notes.md`.

---

## Ã‰tape 3 â€” Agent ReAct avec recherche Tavily (â‰ˆ 25 min)

La recherche web en direct illustre bien l'intÃ©rÃªt d'un agent ReAct (Reasoning + Acting).

```python
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_mistralai.chat_models import ChatMistralAI

search = TavilySearchResults(max_results=2)
tools = [search]

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)

prompt = hub.pull("amalnuaimi/react-mistral")
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

response = agent_executor.invoke({
    "input": "Dois-je prendre un parapluie, sachant que je me rends aujourd'hui et demain Ã  Belfort ?",
    "chat_history": []
})
print(response["output"])
```

ğŸ‘‰ **Exercice 3.1** â€” Ajoutez un second outil (`WikipediaQueryRun`) et observez l'impact sur le plan d'action de l'agent. Analysez le `intermediate_steps` retournÃ© par l'`AgentExecutor`.

ğŸ‘‰ **Exercice 3.2** â€” Modifiez le prompt systÃ¨me pour forcer l'agent Ã  rÃ©pondre en franÃ§ais formel et Ã  citer ses sources.

ğŸ‘‰ **Exercice 3.3** *(optionnel)* â€” Remplacez `ChatMistralAI` par `ChatOpenAI(model_name="gpt-4.1")` et comparez les traces.

---

## Ã‰tape 4 â€” Variante OpenAI & hub ReAct (â‰ˆ 15 min)

Pour comparer facilement deux fournisseurs de LLM :

```python
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_openai import ChatOpenAI

search = TavilySearchResults(max_results=2)
tools = [search]

llm = ChatOpenAI(model_name="gpt-4.1")

prompt = hub.pull("hwchase17/react")
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

response = agent_executor.invoke({
    "input": "Dois-je prendre un parapluie, sachant que je me rends aujourd'hui et demain Ã  Belfort ?"
})
print(response["output"])
```

ğŸ‘‰ **Exercice 4.1** â€” Activez `return_intermediate_steps=True` dans l'exÃ©cuteur et inspectez les requÃªtes envoyÃ©es Ã  Tavily.

ğŸ‘‰ **Exercice 4.2** â€” Mesurez le coÃ»t d'infÃ©rence (`usage_metadata`) pour 3 requÃªtes diffÃ©rentes et construisez un tableau comparatif Mistral vs OpenAI.

---

## Ã‰tape 5 â€” Agents spÃ©cialisÃ©s sur la littÃ©rature scientifique (â‰ˆ 20 min)

Utilisez l'outil `arxiv` pour interroger des publications scientifiques.

```python
from langchain import hub
from langchain.agents import AgentExecutor, create_react_agent, load_tools
from langchain_mistralai.chat_models import ChatMistralAI

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)
tools = load_tools(["arxiv"])

prompt = hub.pull("hwchase17/react")
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

agent_executor.invoke({"input": "RÃ©sume l'article 1605.08386 en franÃ§ais"})
```

ğŸ‘‰ **Exercice 5.1** â€” Explorez `tools[0].name` et `tools[0].description` pour documenter l'outil dans votre readme d'Ã©quipe.

ğŸ‘‰ **Exercice 5.2** â€” CrÃ©ez un prompt personnalisÃ© qui impose la structure suivante : *RÃ©sumÃ©*, *Points clÃ©s*, *Applications potentielles*.

ğŸ‘‰ **Exercice 5.3** *(optionnel)* â€” RÃ©cupÃ©rez le PDF source via l'API arXiv et stockez-le localement pour une utilisation ultÃ©rieure en RAG.

---

## Ã‰tape 6 â€” Agent dÃ©veloppeur : Python REPL (â‰ˆ 20 min)

L'outil `PythonREPLTool` permet Ã  l'agent d'exÃ©cuter du code Python pour rÃ©soudre des problÃ¨mes calculatoires.

```python
from langchain.agents import create_openai_functions_agent
from langchain_experimental.tools import PythonREPLTool
from langchain_openai import ChatOpenAI
from langchain import hub

tools = [PythonREPLTool()]

instructions = """You are an agent designed to write and execute python code to answer questions.
You have access to a python REPL, which you can use to execute python code.
If you get an error, debug your code and try again.
Only use the output of your code to answer the question. 
You might know the answer without running any code, but you should still run the code to get the answer.
If it does not seem like you can write code to answer the question, just return "I don't know" as the answer.
"""

base_prompt = hub.pull("langchain-ai/openai-functions-template")
prompt = base_prompt.partial(instructions=instructions)
agent = create_openai_functions_agent(ChatOpenAI(temperature=0), tools, prompt)

agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "Quel est le milliÃ¨me nombre de Fibonacci ?"})
```

ğŸ‘‰ **Exercice 6.1** â€” Limitez le temps d'exÃ©cution (timeout) de l'exÃ©cuteur et observez le comportement de l'agent en cas de calcul long.

ğŸ‘‰ **Exercice 6.2** â€” Ajoutez un garde-fou : si la sortie dÃ©passe 200 caractÃ¨res, tronquez la rÃ©ponse avant de l'afficher Ã  l'utilisateur.

---

## Ã‰tape 7 â€” Combiner plusieurs outils (â‰ˆ 20 min)

Les agents deviennent plus polyvalents lorsqu'ils orchestrent plusieurs actions.

```python
from langchain.agents import load_tools, create_react_agent
from langchain_openai import OpenAI
from langchain import hub
from langchain.agents import AgentExecutor

llm = OpenAI()
tools = load_tools(["llm-math", "wikipedia"], llm=llm)
prompt = hub.pull("hwchase17/react")

agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    handle_parsing_errors=True,
    verbose=True
)

agent_executor.invoke({"input": "Qu'est-ce que 25% de 300?"})
```

ğŸ‘‰ **Exercice 7.1** â€” Ajoutez un outil personnalisÃ© qui convertit les devises (en interrogeant une API ou une table statique) et obligez l'agent Ã  l'utiliser via un message systÃ¨me.

ğŸ‘‰ **Exercice 7.2** â€” Observez le champ `handle_parsing_errors` : dÃ©sactivez-le volontairement pour constater l'erreur et rÃ©digez un mÃ©mo expliquant quand l'activer.

---

## Ã‰tape 8 â€” Concevoir vos propres outils (â‰ˆ 25 min)

Vous pouvez exposer de simples fonctions Python sous forme d'outils LangChain.

```python
from langchain_core.tools import tool

@tool
def multiply(first_int: int, second_int: int) -> int:
    """Multiplie deux entiers."""
    return first_int * second_int

@tool
def add(first_int: int, second_int: int) -> int:
    "Ajoute deux entiers."
    return first_int + second_int

@tool
def exponentiate(base: int, exponent: int) -> int:
    "Calcule la puissance d'un entier donnÃ©."
    return base**exponent
```

```python
from langchain import hub
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model_name="gpt-4.1")

tools = [multiply, add, exponentiate]
prompt = hub.pull("hwchase17/openai-tools-agent")
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

agent_executor.invoke({
    "input": "Porter 3 Ã  la puissance 5 et multiplier le rÃ©sultat par la somme de douze et de trois, puis Ã©lever le tout au carrÃ©."
})
```

ğŸ‘‰ **Exercice 8.1** â€” Ajoutez la validation des types (conversion en `int`) dans vos outils et gÃ©rez les erreurs utilisateur.

ğŸ‘‰ **Exercice 8.2** â€” CrÃ©ez un outil `log_to_file` qui enregistre chaque opÃ©ration dans un fichier `operations.log`.

ğŸ‘‰ **Exercice 8.3** *(optionnel)* â€” DÃ©finissez un `StructuredTool` pour exposer un schÃ©ma JSON prÃ©cis aux agents.

---

## Ã‰tape 9 â€” Vers l'assemblage multi-agents (â‰ˆ 20 min)

Lorsque les besoins deviennent complexes, il est pertinent d'orchestrer plusieurs agents spÃ©cialisÃ©s (recherche, calcul, synthÃ¨se...).

1. DÃ©finissez un agent `chercheur` spÃ©cialisÃ© en recherche documentaire (Tavily + arXiv).
2. CrÃ©ez un agent `analyste` qui rÃ©sume et compare les informations (Python REPL + outils mathÃ©matiques).
3. Utilisez un contrÃ´leur (script Python ou LangGraph) pour orchestrer les appels successifs.

![SchÃ©ma de collaboration multi-agents](img/rag2.png)

ğŸ‘‰ **Exercice 9.1** â€” Dessinez un diagramme sÃ©quentiel illustrant l'orchestration entre deux agents et un exÃ©cuteur final.

ğŸ‘‰ **Exercice 9.2** â€” ImplÃ©mentez un script minimal qui enchaÃ®ne deux `AgentExecutor` et compare les rÃ©ponses (temps, coÃ»t, qualitÃ©).

ğŸ‘‰ **Exercice 9.3** *(optionnel)* â€” Explorez [LangGraph](https://python.langchain.com/docs/langgraph) pour modÃ©liser ce flot de contrÃ´le.

---

## Pour aller plus loin

- ExpÃ©rimentez l'intÃ©gration d'un **RAG** avec un agent (vector store + outils de recherche personnalisÃ©s).
- DÃ©ployez vos agents dans un environnement serveur (FastAPI, Streamlit) et mesurez les performances.
- Ã‰tudiez les mÃ©canismes de **sÃ©curitÃ©** (guardrails, filtrage des prompts) pour des dÃ©ploiements en production.

Bonne exploration !
