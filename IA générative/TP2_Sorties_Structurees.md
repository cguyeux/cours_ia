# TP2 ‚Äî Sorties structur√©es avec LangChain et Mistral (‚âà 1h30)

[‚¨ÖÔ∏è Retour au sommaire](../LISEZMOI.md)

## Objectifs

- Comprendre l'int√©r√™t des **sorties structur√©es** pour fiabiliser les r√©ponses d'un LLM.
- Mettre en place des sch√©mas Pydantic et les utiliser avec `with_structured_output`.
- Explorer plusieurs formats de sortie : bool√©en, classe, entier, traduction, raisonnement pas √† pas.
- Industrialiser les r√©sultats (post-traitement, extraction d'informations) au sein d'une cha√Æne LangChain.

## Pr√©requis

- Avoir r√©alis√© (ou parcouru) le [TP1 ‚Äî Premiers pas avec la g√©n√©ration de texte](TP1_LangChain_Mistral.md).
- Python ‚â• 3.10, un environnement virtuel actif et la biblioth√®que `langchain-mistralai` install√©e.
- Une cl√© API Mistral AI valide plac√©e dans vos variables d'environnement.

## √âtape 1 ‚Äî Pourquoi structurer les sorties ? (‚âà 10 min)

Sans contrainte, un mod√®le peut r√©pondre dans un format impr√©visible. Les **sorties structur√©es** permettent :

- d'imposer un sch√©ma de validation (types, valeurs minimales / maximales, listes d'options) ;
- d'√©viter des parsings fragiles (regex, JSON non valide, etc.) ;
- de faciliter la consommation des r√©sultats dans vos applications.

üëâ **Exercice 1.1** ‚Äî Listez deux sc√©narios m√©tiers o√π recevoir une sortie strictement structur√©e est indispensable.

üëâ **Exercice 1.2** ‚Äî Dans votre propre exp√©rience, quels probl√®mes avez-vous d√©j√† rencontr√©s √† cause de sorties libres de LLM ?

## √âtape 2 ‚Äî Cas simple : r√©ponse bool√©enne (‚âà 15 min)

Cr√©ez un fichier `tp2_bool.py` avec le contenu suivant :

```python
from pydantic import BaseModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_mistralai.chat_models import ChatMistralAI

class Answer(BaseModel):
    answer: bool

prompt_answer = [
    ("system", "Tu es un assistant charg√© de r√©pondre un bool√©en (True ou False) √† la question d'un utilisateur."),
    ("human", "{question}")
]

prompt_answer_template = ChatPromptTemplate.from_messages(prompt_answer)
llm = ChatMistralAI(model="mistral-large-latest", temperature=0)
chain = prompt_answer_template | llm.with_structured_output(schema=Answer)

def repond(question):
    return chain.invoke({"question": question}).answer

for question in ["No√´l est en hiver", "Il pleut quand il pleut pas"]:
    print(question)
    reponse = repond(question)
    print(f"R√©ponse : {reponse} (type : {type(reponse)})")
    print()
```

üëâ **Exercice 2.1** ‚Äî Ajoutez un troisi√®me exemple de question ambig√ºe. Observez la sortie et discutez de la fa√ßon dont le prompt pourrait √™tre renforc√©.

üëâ **Exercice 2.2** ‚Äî V√©rifiez le type Python retourn√©. Pourquoi est-ce important pour la suite de votre application ?

## √âtape 3 ‚Äî Choisir une action pr√©d√©finie (‚âà 20 min)

Nous pouvons imposer une liste d'actions possibles. Cr√©ez `tp2_action.py` :

```python
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_mistralai.chat_models import ChatMistralAI

tasks = ["R√©pondre √† une nouvelle question", "Fournir plus d'√©l√©ments √† la question pr√©c√©dente"]

class NextTask(BaseModel):
    """Utilise toujours cet outil pour structurer ta r√©ponse to the user."""
    action: str = Field(
        ...,
        enum=tasks,
        description="La prochaine action √† mener"
    )

prompt_message = [
    ("system", "Tu es un assistant charg√© de classifier la demande d'un utilisateur parmi une liste r√©duite d'actions √† mener en tant que chatbot. Tu dois d√©terminer la prochaine action √† mener."),
    ("human", "{text}")
]

prompt = ChatPromptTemplate.from_messages(prompt_message)
llm = ChatMistralAI(model="mistral-large-latest", temperature=0)
chain = prompt | llm.with_structured_output(schema=NextTask)

for text in ["Peux-tu m'en dire plus", "Que sont les PPV ?"]:
    print(text)
    print(chain.invoke({"text": text}))
    print()
```

üëâ **Exercice 3.1** ‚Äî Ajoutez une troisi√®me action (¬´ Demander une clarification ¬ª) et v√©rifiez que le LLM la s√©lectionne lorsqu'un utilisateur est confus.

üëâ **Exercice 3.2** ‚Äî Comparez la robustesse de ce sch√©ma structur√© √† une simple r√©ponse textuelle : que se passe-t-il si le mod√®le hallucine ?

## √âtape 4 ‚Äî Quantifier un comportement : note enti√®re (‚âà 15 min)

Passons √† un score num√©rique. Cr√©ez `tp2_ton.py` :

```python
from pydantic import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_mistralai.chat_models import ChatMistralAI

class TonMessage(BaseModel):
    """√âvaluation du ton du message de l'utilisateur."""
    note_ton: int = Field(
        ...,
        ge=1,
        le=5,
        description="Note attribu√©e au ton du message : 1 pour neutre, 5 pour tr√®s aimable"
    )

prompt_message = [
    ("system", "Tu es un assistant charg√© d'√©valuer le ton d'un message donn√© par l'utilisateur. Attribue une note de 1 √† 5 au ton du message, o√π 1 signifie neutre et 5 signifie tr√®s aimable."),
    ("human", "{text}")
]

prompt = ChatPromptTemplate.from_messages(prompt_message)
llm = ChatMistralAI(model="mistral-large-latest", temperature=0)
chain = prompt | llm.with_structured_output(schema=TonMessage)

messages = [
    "Bonjour, pourrais-tu m'aider s'il te pla√Æt ?",
    "J'ai besoin de √ßa imm√©diatement.",
    "Merci beaucoup pour ton aide pr√©cieuse !"
]

for text in messages:
    print(f"Message : {text}")
    print(chain.invoke({"text": text}))
    print()
```

üëâ **Exercice 4.1** ‚Äî Ajoutez un champ `commentaire: str` pour expliquer la note. Quelle consigne ajouter dans le prompt syst√®me ?

üëâ **Exercice 4.2** ‚Äî Transformez ce score en m√©trique agr√©g√©e : calculez la moyenne de `note_ton` sur une liste de messages et affichez le r√©sultat.

## √âtape 5 ‚Äî Forcer un format JSON exploitable (‚âà 20 min)

M√™me avec un prompt clair, le mod√®le peut r√©pondre librement :

```python
from langchain_mistralai.chat_models import ChatMistralAI
from langchain_core.messages import HumanMessage

llm = ChatMistralAI(model="mistral-medium-latest")
message = HumanMessage(content="Peux-tu me traduire ce qui suit, en anglais ?\n\n Quelle est la capitale de l'Albanie ?")
print(llm.invoke([message]))
```

Pour garantir un JSON valide, imposez un sch√©ma `Translation` :

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from langchain_mistralai.chat_models import ChatMistralAI
from pydantic import BaseModel, Field

class Translation(BaseModel):
    original_text: str = Field(..., description="The original text before translation in another language")
    original_language: str = Field(..., description="The original language before translation")
    translated_text: str = Field(..., description="The final text after translation in another language")
    translated_language: str = Field(..., description="The language into which the translation must be done")

def traduit(texte, langue_source="fran√ßais", langue_cible="anglais"):
    llm = ChatMistralAI(model_name="mistral-medium-latest")
    prompt = ChatPromptTemplate.from_template("""Je souhaite que tu traduises le texte suivant du {langue_source} vers le {langue_cible}. Ta traduction doit √™tre pr√©cise, fluide et naturelle, et pr√©server parfaitement le sens original. 
    Retourne-moi la r√©ponse sous forme d'objet JSON avec les champs :
      - original_text : le texte original
      - original_language : la langue du texte original
      - translated_text : la traduction du texte
      - translated_language : la langue de la traduction

    Voici le texte √† traduire :
    ----
    {texte}""")
    output_parser = StrOutputParser()
    extract_translation = RunnableLambda(lambda translation: translation.translated_text)
    chain0 = prompt | llm.with_structured_output(Translation) | extract_translation
    return chain0.invoke({
        "langue_source": langue_source,
        "langue_cible": langue_cible,
        "texte": texte
    })

print(traduit("Quelle est la capitale de l'Albanie"))
```

üëâ **Exercice 5.1** ‚Äî Supprimez temporairement `RunnableLambda`. Que r√©cup√©rez-vous ? Comment pourriez-vous exploiter l'objet complet ?

üëâ **Exercice 5.2** ‚Äî Modifiez la fonction pour prendre en charge d'autres couples de langues. Ajoutez un contr√¥le qui l√®ve une exception si `langue_cible` n'est pas support√©e.

## √âtape 6 ‚Äî Structurer un raisonnement pas √† pas (‚âà 15 min)

Les sorties structur√©es peuvent guider un raisonnement √©l√©mentaire :

```python
from pydantic import BaseModel
from langchain_core.prompts import ChatPromptTemplate
from langchain_mistralai.chat_models import ChatMistralAI

class Etape(BaseModel):
    explication: str
    sortie: str

class MathReponse(BaseModel):
    etapes: list[Etape]
    reponse_finale: str

prompt_answer = [
    ("system", "Tu es un professeur de math√©matiques tr√®s p√©dagogue."),
    ("human", "{exercice}")
]

prompt_answer_template = ChatPromptTemplate.from_messages(prompt_answer)
llm = ChatMistralAI(model="mistral-large-latest", temperature=0)
chain = prompt_answer_template | llm.with_structured_output(schema=MathReponse)

explications = chain.invoke({"exercice": "R√©sous  8x + 31 = 2"})
for etape in explications.etapes:
    print(f"- {etape.explication}")
    print(f"  Le r√©sultat est alors : {etape.sortie}")

print(f"Au final, on trouve : {explications.reponse_finale}")
```

üëâ **Exercice 6.1** ‚Äî Ajoutez un champ `verifications: list[str]` pour forcer le mod√®le √† contr√¥ler sa solution.

üëâ **Exercice 6.2** ‚Äî Testez le prompt sur d'autres √©quations. Quelles limites identifiez-vous ? (par exemple, expressions non lin√©aires, fractions complexes...)

## Pour aller plus loin

- Explorez les agents LangChain capables de combiner plusieurs outils structur√©s.
- Connectez ces sch√©mas √† un stockage de donn√©es (base SQL, vector store) pour automatiser des workflows.
- Comparez le comportement avec d'autres fournisseurs (OpenAI, Anthropic) : les sch√©mas Pydantic restent compatibles.

Bon TP !
